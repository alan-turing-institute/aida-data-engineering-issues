{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and data wrangling for Ofcom broadband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis we are comparing different standard classifiers with the task of detecting whether a broadband connection belongs to an urban or a rural area. The models are trained and validated with the 2014 and 2015 datasets and they are tested in the 2016 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load both the 2014, 2015 and 2016 datasets into a proper format (DP). Notice that in some of the datasets we needed to discard some lines from the beginning of the files to locate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../../broadband_downloaded/'\n",
    "\n",
    "data_2014_05 = pd.read_csv(folder + '2014_05/panellist_data.csv', encoding = \"ISO-8859-1\",header=3)\n",
    "data_2014_11 = pd.read_csv(folder + '2014_11/panellist_data_november_2014.csv')\n",
    "data_2015 = pd.read_csv(folder + '2015_11/panellist-data.csv')\n",
    "data_2016 = pd.read_csv(folder + '2016_11/UK-home-broadband-performance,-November-2016-Panellist-data.csv',header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, each table have a different format, with different features, same features with different names, etc. Since we want to concatenate the tables from 2014 and 2015, we need to agree on a common format for the integration (DI).\n",
    "\n",
    "To do this, we only keep for each dataset the Id, Urban/rural, Download 24h, Upload 24h, Latency 24h and Web 24h features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2014-05\n",
    "features = ['ID', 'Urban/rural', 'Download speed (Mbit/s) 24 hrs', 'Upload speed (Mbit/s)24-hour',\n",
    "       'Latency (ms)24-hour','Web page (ms)24-hour']\n",
    "data_2014_05 = data_2014_05[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2014-11\n",
    "features = ['Id', 'Urban/rural', 'Download speed (Mbit/s) 24 hrs', 'Upload speed (Mbit/s)24-hour',\n",
    "       'Latency (ms)24-hour','Web page (ms)24-hour']\n",
    "data_2014_11 = data_2014_11[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015-11\n",
    "features = ['unit_id', 'URBAN2', 'DL24hrmean', 'UL24hrmean', \n",
    "            'Latency24hr', 'Web24hr']\n",
    "data_2015 = data_2015[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016-11\n",
    "features = ['unit_id', 'Urban_Rural', 'trim24_mean_download', 'trim4_mean_upload',\n",
    "            'latencyloss24','webget24']\n",
    "data_2016 = data_2016[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename headers of all tables\n",
    "features = ['Id','Urban/Rural','Download speed','Upload speed','Latency','Web page']\n",
    "data_2014_05.columns = features\n",
    "data_2014_11.columns = features\n",
    "data_2015.columns = features\n",
    "data_2016.columns = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 2015 dataset, they introduce the category 'semi-urban'. We have decided to keep it as is, disregarding that there might exist 'semi-urban' instances across 2014 or 2016 that were not encoded as such (NS).\n",
    "\n",
    "We concatenate 2014_05, 2014_11 and 2015 into a single table, which is going to be the data used for training (DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.concat([data_2014_05,data_2014_11,data_2015],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several Broadband devices were measured during several years, meaning that we have duplicates in our data that need to be removed according to the 'Id'. We will keep the newest recording in the training data (DI - Deduplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = X_train_df['Id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique_df = pd.DataFrame(columns=features)\n",
    "\n",
    "for nn in range(X_train_df.shape[0]):\n",
    "    if counts[X_train_df['Id'].iloc[nn]] > 1:\n",
    "        counts[X_train_df['Id'].iloc[nn]] -= 1\n",
    "    else:\n",
    "        X_train_unique_df = X_train_unique_df.append(X_train_df.iloc[nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove possible duplicates from the test set (2016) of existing broadband devices in the training set (DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in X_train_unique_df['Id']:\n",
    "    data_2016.drop(data_2016[data_2016['Id'] == elem].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data has several missing entries in the urban/rural, latency and web page features, that correspond to less than 1% of the data. We decided to remove those entries from the analysis (MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nan = X_train_unique_df[X_train_unique_df['Urban/Rural'].isnull()].index\n",
    "X_train_unique_df.drop(index_nan,inplace=True)\n",
    "\n",
    "index_nan = X_train_unique_df[X_train_unique_df['Latency'].isnull()].index\n",
    "X_train_unique_df.drop(index_nan,inplace=True)\n",
    "\n",
    "index_nan = X_train_unique_df[X_train_unique_df['Web page'].isnull()].index\n",
    "X_train_unique_df.drop(index_nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the Urban/Rural feature into an ordinal variable (0: Rural, 1: Semi-urban, 2: Urban) (FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urban_classes(x):\n",
    "#     codes = dict({'Rural':0, 'Semi-urban':1, 'Urban':2})\n",
    "    codes = dict({'Rural':0, 'Semi-urban':0, 'Urban':1})\n",
    "    return codes[x]\n",
    "\n",
    "X_train_unique_df['Urban/Rural'] = X_train_unique_df['Urban/Rural'].apply(urban_classes)\n",
    "data_2016['Urban/Rural'] = data_2016['Urban/Rural'].apply(urban_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary features (Id), standardize the data and create X and y training and test for a multiclass logistic regression problem (Classify the broadband according to rural or urban based on the speeds of the devices) (FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification problems\n",
    "X_train_unique_df.drop(columns='Id',inplace=True)\n",
    "data_2016.drop(columns='Id',inplace=True)\n",
    "\n",
    "y_train = X_train_unique_df['Urban/Rural']\n",
    "y_test = data_2016['Urban/Rural']\n",
    "\n",
    "X_train_unique_df.drop(columns='Urban/Rural',inplace=True)\n",
    "data_2016.drop(columns='Urban/Rural',inplace=True)\n",
    "\n",
    "X_train_mean = X_train_unique_df.mean()\n",
    "X_train_std = X_train_unique_df.std()\n",
    "X_train = (X_train_unique_df - X_train_mean)/X_train_std\n",
    "X_test = (data_2016 - X_train_mean)/X_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification comparison - with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic parameters:\n",
      "{'C': 0.1, 'penalty': 'l2'}\n",
      "Naive Bayes parameters:\n",
      "{'priors': None}\n",
      "Support Vector Classification parameters:\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "Random Forest parameters:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Setting parameters with grid search\n",
    "lr = LogisticRegression(multi_class='auto')\n",
    "gnb = GaussianNB()\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "params_lr = {'penalty':['l2'], 'C':[0.1,1,10,100]}\n",
    "parmas_gnb = {'priors':[None]}\n",
    "params_svc = {'kernel':['linear','rbf'],'C':[0.1,1,10,100]}\n",
    "params_rfc = {'max_depth':[None,2,3,4,10],'n_estimators':[10,100,200,500]}\n",
    "\n",
    "classifiers = dict()\n",
    "for clf, name, params in [(lr, 'Logistic', params_lr),\n",
    "                  (gnb, 'Naive Bayes', parmas_gnb),\n",
    "                  (svc, 'Support Vector Classification', params_svc),\n",
    "                  (rfc, 'Random Forest', params_rfc)]:\n",
    "    \n",
    "    clf_grid = GridSearchCV(clf, params, cv=3)\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    #Select best model\n",
    "    best_model = clf_grid.cv_results_['rank_test_score'].argmin()\n",
    "    params_best_model = clf_grid.cv_results_['params'][best_model]\n",
    "    \n",
    "    #Test classifier\n",
    "    clf.set_params(**params_best_model)\n",
    "    \n",
    "    classifiers[name] = clf\n",
    "    \n",
    "    print(name + ' parameters:')\n",
    "    print(params_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic train accuracy: 0.6975\n",
      "Logistic train F1: 0.8039\n",
      "Logistic test accuracy: 0.7764\n",
      "Logistic test F1: 0.8582\n",
      "Logistic test precision: 0.7933\n",
      "Logistic test recall: 0.9347\n",
      "Confusion matrix train: \n",
      "[[ 291  965]\n",
      " [ 168 2322]]\n",
      "Confusion matrix test: \n",
      "[[ 275  485]\n",
      " [ 130 1861]]\n",
      "Naive Bayes train accuracy: 0.6925\n",
      "Naive Bayes train F1: 0.7945\n",
      "Naive Bayes test accuracy: 0.7666\n",
      "Naive Bayes test F1: 0.8477\n",
      "Naive Bayes test precision: 0.8031\n",
      "Naive Bayes test recall: 0.8975\n",
      "Confusion matrix train: \n",
      "[[ 367  889]\n",
      " [ 263 2227]]\n",
      "Confusion matrix test: \n",
      "[[ 322  438]\n",
      " [ 204 1787]]\n",
      "Support Vector Classification train accuracy: 0.705\n",
      "Support Vector Classification train F1: 0.8134\n",
      "Support Vector Classification test accuracy: 0.7644\n",
      "Support Vector Classification test F1: 0.8548\n",
      "Support Vector Classification test precision: 0.7718\n",
      "Support Vector Classification test recall: 0.9578\n",
      "Confusion matrix train: \n",
      "[[ 232 1024]\n",
      " [  81 2409]]\n",
      "Confusion matrix test: \n",
      "[[ 196  564]\n",
      " [  84 1907]]\n",
      "Random Forest train accuracy: 0.7184\n",
      "Random Forest train F1: 0.8215\n",
      "Random Forest test accuracy: 0.7866\n",
      "Random Forest test F1: 0.8689\n",
      "Random Forest test precision: 0.7824\n",
      "Random Forest test recall: 0.9769\n",
      "Confusion matrix train: \n",
      "[[ 263  993]\n",
      " [  62 2428]]\n",
      "Confusion matrix test: \n",
      "[[ 219  541]\n",
      " [  46 1945]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pos = np.argwhere(y_test.values==1)\n",
    "y_test_neg = np.argwhere(y_test.values==0)\n",
    "\n",
    "for name in classifiers:\n",
    "    classifiers[name].fit(X_train, y_train)\n",
    "    \n",
    "    #Accuracy\n",
    "    y_train_est = classifiers[name].predict(X_train)\n",
    "    y_test_est = classifiers[name].predict(X_test)\n",
    "    \n",
    "    #Precision - recall - f1 score\n",
    "    TP = sum((y_test.values==y_test_est)[y_test_pos])[0]\n",
    "    TN = sum((y_test.values==y_test_est)[y_test_neg])[0]\n",
    "    FP = sum((y_test.values!=y_test_est)[y_test_neg])[0]\n",
    "    FN = sum((y_test.values!=y_test_est)[y_test_pos])[0]\n",
    "    \n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "#     f1 = 2/(1/prec + 1/rec)\n",
    "    \n",
    "    print(name + ' train accuracy: ' + str((y_train_est == y_train).mean().round(4)))\n",
    "    print(name + ' train F1: ' + str(f1_score(y_train,y_train_est).round(4)))\n",
    "    print(name + ' test accuracy: ' + str((y_test_est == y_test).mean().round(4)))\n",
    "    print(name + ' test F1: ' + str(f1_score(y_test,y_test_est).round(4)))\n",
    "    print(name + ' test precision: ' + str(prec.round(4)))\n",
    "    print(name + ' test recall: ' + str(rec.round(4)))\n",
    "    \n",
    "    print('Confusion matrix train: ')\n",
    "    print(confusion_matrix(y_train,y_train_est))\n",
    "    \n",
    "    print('Confusion matrix test: ')\n",
    "    print(confusion_matrix(y_test,y_test_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
